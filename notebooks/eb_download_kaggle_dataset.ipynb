{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development and testing ideas\n",
    "\n",
    "by Edgar Bermudez\n",
    "\n",
    "June, 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "KAGGLE_API_KEY = os.getenv(\"KAGGLE_API_KEY\")\n",
    "KAGGLE_USERNAME = os.getenv(\"KAGGLE_USERNAME\")\n",
    "\n",
    "if not KAGGLE_API_KEY or not KAGGLE_USERNAME:\n",
    "    raise ValueError(\"KAGGLE_API_KEY or KAGGLE_USERNAME is not set\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# load the kaggle api\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "\n",
    "def download_dataset(dataset_path, output_path):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Initialize and authenticate the API\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    \n",
    "    print(f\"Downloading dataset: {dataset_path}\")\n",
    "    api.dataset_download_files(\n",
    "        dataset=dataset_path,  # Full path: owner/dataset-name\n",
    "        path=output_path,\n",
    "        unzip=True\n",
    "    )\n",
    "    print(f\"Dataset downloaded and extracted to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function\n",
    "\n",
    "# dataset example and path\n",
    "dataset_name = \"titanic/titanic\"\n",
    "download_path = \"data/raw\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset: titanic/titanic\n",
      "Dataset URL: https://www.kaggle.com/datasets/titanic/titanic\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/datasets/download/titanic/titanic?raw=false",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test with Titanic dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdownload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtitanic/titanic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/raw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mdownload_dataset\u001b[39m\u001b[34m(dataset_path, output_path)\u001b[39m\n\u001b[32m     10\u001b[39m api.authenticate()\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_download_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Full path: owner/dataset-name\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43munzip\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset downloaded and extracted to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle_explorer/.venv/lib/python3.12/site-packages/kaggle/api/kaggle_api_extended.py:1664\u001b[39m, in \u001b[36mKaggleApi.dataset_download_files\u001b[39m\u001b[34m(self, dataset, path, force, quiet, unzip, licenses)\u001b[39m\n\u001b[32m   1662\u001b[39m request.dataset_slug = dataset_slug\n\u001b[32m   1663\u001b[39m request.dataset_version_number = dataset_version_number\n\u001b[32m-> \u001b[39m\u001b[32m1664\u001b[39m response = \u001b[43mkaggle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1666\u001b[39m outfile = os.path.join(effective_path, dataset_slug + \u001b[33m'\u001b[39m\u001b[33m.zip\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1667\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.download_needed(response, outfile, quiet):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle_explorer/.venv/lib/python3.12/site-packages/kagglesdk/datasets/services/dataset_api_service.py:80\u001b[39m, in \u001b[36mDatasetApiClient.download_dataset\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m request \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m   request = ApiDownloadDatasetRequest()\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatasets.DatasetApiService\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mApiDownloadDataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHttpRedirect\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle_explorer/.venv/lib/python3.12/site-packages/kagglesdk/kaggle_http_client.py:126\u001b[39m, in \u001b[36mKaggleHttpClient.call\u001b[39m\u001b[34m(self, service_name, request_name, request, response_type)\u001b[39m\n\u001b[32m    123\u001b[39m settings = \u001b[38;5;28mself\u001b[39m._session.merge_environment_settings(http_request.url, {}, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    124\u001b[39m http_response = \u001b[38;5;28mself\u001b[39m._session.send(http_request, **settings)\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle_explorer/.venv/lib/python3.12/site-packages/kagglesdk/kaggle_http_client.py:191\u001b[39m, in \u001b[36mKaggleHttpClient._prepare_response\u001b[39m\u001b[34m(self, response_type, http_response)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prepare_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, response_type, http_response):\n\u001b[32m    190\u001b[39m   \u001b[38;5;28mself\u001b[39m._print_response(http_response)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m   \u001b[43mhttp_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m http_response.headers[\u001b[33m'\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m    193\u001b[39m     resp = http_response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/kaggle_explorer/.venv/lib/python3.12/site-packages/requests/models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1019\u001b[39m     http_error_msg = (\n\u001b[32m   1020\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1021\u001b[39m     )\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/datasets/download/titanic/titanic?raw=false"
     ]
    }
   ],
   "source": [
    "# Test with Titanic dataset\n",
    "download_dataset(dataset_path=\"titanic/titanic\", output_path=\"data/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "load_dotenv()\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "def download_competition_dataset(competition_name, output_path):\n",
    "    \"\"\"\n",
    "    Download a competition dataset from Kaggle.\n",
    "\n",
    "    Args:\n",
    "        competition_name (str): The name of the competition.\n",
    "        output_path (str): The path to the output directory.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # get the repo root directory (parent of the notebooks directory)\n",
    "    repo_root = Path(os.getcwd()).parent\n",
    "\n",
    "    # create the output path\n",
    "    output_path = os.path.join(repo_root, output_path)\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Initialize and authenticate the API\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    \n",
    "    print(f\"Downloading competition dataset: {competition_name}\")\n",
    "    api.competition_download_files(\n",
    "        competition=competition_name,\n",
    "        path=output_path,\n",
    "        quiet=False\n",
    "    )\n",
    "    print(f\"Dataset downloaded to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading competition dataset: titanic\n",
      "Downloading titanic.zip to /home/edgar/projects/kaggle_explorer/data/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34.1k/34.1k [00:00<00:00, 24.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset downloaded to: /home/edgar/projects/kaggle_explorer/data/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with Titanic competition\n",
    "download_competition_dataset(competition_name=\"titanic\", output_path=\"data/raw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_submission.csv\n",
      "test.csv\n",
      "train.csv\n"
     ]
    }
   ],
   "source": [
    "# unzip the dataset and explore the files\n",
    "\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "# parameterize the dataset paths\n",
    "dataset_zip_path = Path('data/raw/titanic.zip')\n",
    "extraction_dir = Path('data/raw/titanic')\n",
    "\n",
    "# unzip the dataset\n",
    "with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_dir)\n",
    "\n",
    "# explore the files\n",
    "for file in extraction_dir.iterdir():\n",
    "    print(file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out if the dataset is already divided into train and test sets\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# get the dataset path\n",
    "dataset_path = \"data/raw/titanic\"\n",
    "\n",
    "# get the files in the dataset path\n",
    "files = os.listdir(dataset_path)\n",
    "\n",
    "if \"train.csv\" in files and \"test.csv\" in files:\n",
    "    print(\"The dataset is already divided into train and test sets\")\n",
    "    divided = True\n",
    "else:\n",
    "    print(\"The dataset is not already divided into train and test sets\")\n",
    "    divided = False\n",
    "\n",
    "# if the dataset is divided into train and test sets, read the train and test files\n",
    "if divided:\n",
    "    train_file = os.path.join(dataset_path, \"train.csv\")\n",
    "    test_file = os.path.join(dataset_path, \"test.csv\")\n",
    "\n",
    "    # read the train and test files\n",
    "    train_df = pd.read_csv(train_file)\n",
    "    test_df = pd.read_csv(test_file)\n",
    "\n",
    "else:\n",
    "    # read the dataset\n",
    "    df = pd.read_csv(os.path.join(dataset_path, \"train.csv\"))\n",
    "\n",
    "    # split the dataset into train and test\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
